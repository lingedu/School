{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.tensor as tensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x_train, t_train, x_test, t_test = mnist.load()\n",
    "xtrain=tensor(x_train/255,dtype=torch.float)\n",
    "ttrain=tensor(t_train,dtype=torch.int64)\n",
    "xtest=tensor(x_test/255,dtype=torch.float)\n",
    "ttest=tensor(t_test,dtype=torch.int64)\n",
    "\n",
    "plt.imshow(xtrain[1].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(256, 120)#(28-4)/2=12,(12-4)/2=4(size=4*4), there are 16 filters\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,256)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        #x=F.softmax(self.fc2(x),dim=1)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.659353017807\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() # mean square error loss\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "Loss=0\n",
    "from time import time\n",
    "stime=time()\n",
    "for epoch in range(1):\n",
    "    for i,x in enumerate(xtrain):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x.view(-1,1,28,28))\n",
    "        loss = criterion(y, tensor([ttrain[i]]))\n",
    "        Loss+=loss.item()\n",
    "        #if i%2000==1999: \n",
    "            \n",
    "            #print('epoch: ', epoch, 'loss:', (Loss/(2000)))\n",
    "            #Loss=0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(time()-stime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ypred=net(xtest.view(-1,1,28,28))\n",
    "\n",
    "print(ypred.max(1)[1])\n",
    "print(ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp=ttest.eq(ypred.max(1)[1])\n",
    "true=len([x for x in cmp if x==1])\n",
    "false=len([x for x in cmp if x==0])\n",
    "total=true+false\n",
    "print(true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
